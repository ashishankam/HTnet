Micro-expressions are brief, involuntary facial expressions that reveal hidden emotions and typically last between 1/25 and 1/5 of a second, making them difficult to detect due to their subtle muscle movements. Current deep learning models struggle with this fine-grained recognition because global self-attention mechanisms often miss localized facial cues. To overcome these challenges, the Hierarchical Transformer Network (HTNet) was proposed, leveraging transformer architectures to capture both local and global features by dividing the face into four key regions— left eye, right eye, left lip, and right lip—and applying multi-level self-attention. HTNet’s hierarchical design integrates short- and long-range dependencies, while an aggregation layer fuses features to enhance facial dynamics representation. Evaluated on datasets like SAMM, CASME II, and CAS(ME)³, HTNet achieved state-of-the-art results, demonstrating its effectiveness for emotion analysis and human-computer interaction applications.
Objectives: 
•	Develop HTNet to accurately recognize micro-expressions by focusing on key facial regions and combining local and global features using self-attention.
•	Enhance detection using optical flow and facial landmarks for precise movement tracking.
•	Validate performance on benchmark datasets and optimize the model for real-time use.
•	Address environmental challenges and explore applications in lie detection, mental health, HCI, and emotion recognition.
